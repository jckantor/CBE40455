{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating features in a feature layer\n",
    "\n",
    "As content publishers, you may be required to keep certain web layers up to date. As new data arrives, you may have to append new features, update existing features etc. There are a couple of different options to accomplish this:\n",
    " \n",
    " - Method 1: editing individual features as updated datasets are available\n",
    " - Method 2: overwriting feature layers altogether with updated datasets\n",
    " \n",
    "Depending on the number of features that are updated, your workflow requirements, you may adopt either or both kinds of update mechanisms.\n",
    "\n",
    "In this sample, we explore the first method:\n",
    "\n",
    "**Method 1**\n",
    " - [Updating feature layer by editing individual features](#Updating-feature-layer-by-editing-individual-features)\n",
    "  - [Publish the cities feature layer using the initial dataset](#Publish-the-cities-feature-layer-using-the-initial-dataset)  \n",
    "  - [Apply updates from the second spreadsheet](#Apply-updates-from-the-second-spreadsheet)\n",
    "    - [Identifying existing features that need to be updated](#Identifying-existing-features-that-need-to-be-updated)\n",
    "    - [Perform updates to the existing features](#Perform-updates-to-the-existing-features)\n",
    "    - [Identifying new features that need to be added](#Identifying-new-features-that-need-to-be-added)\n",
    "    - [Adding new features](#Adding-new-features)   \n",
    "  - [Apply edits from third spreadsheet](#Apply-edits-from-third-spreadsheet)\n",
    "    - [Inspecting existing fields of the feature layer](#Inspecting-existing-fields-of-the-feature-layer)\n",
    "    - [Preparing additional columns to add to the feature layer](#Preparing-additional-columns-to-add-to-the-feature-layer)\n",
    "    - [Adding additional columns to the feature layer](#Adding-additional-fields-to-the-feature-layer)\n",
    "    - [Adding attribute values to the new columns](#Adding-attribute-values-to-the-new-columns)\n",
    "\n",
    "For **Method 2**, refer to the sample titled [Overwriting feature layers](/python/sample-notebooks/overwriting-feature-layers)\n",
    "\n",
    "**Note**: To run this sample, you need the ``pandas`` library in your conda environment. If you don't have the library, install it by running the following command from cmd.exe or your shell\n",
    "```\n",
    "conda install pandas```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to the GIS\n",
    "from arcgis.gis import GIS\n",
    "from arcgis import features\n",
    "from getpass import getpass #to accept passwords in an interactive fashion\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "#Access the portal using \"amazing_arcgis_123\" as password for the given Username. \n",
    "password = getpass()\n",
    "gis = GIS(\"https://python.playground.esri.com/portal\", \"arcgis_python\", password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating feature layer by editing individual features\n",
    "\n",
    "Let us consider a scenario where we need to update a feature layer containing the capital cities of the US. We have 3 csv datasets simulating an update workflow as described below:\n",
    "\n",
    " 1. capitals_1.csv -- contains the initial, incomplete dataset\n",
    " 2. capitals_2.csv -- contains additional points and updates to existing points, building on top of capitals_1.csv\n",
    " 3. capitals_annex.csv -- an alternate table containing additional attribute information\n",
    " \n",
    "Our goal is to update the feature layer with each of these datasets doing the necessary edit operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish the cities feature layer using the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>capital</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2007</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>State</td>\n",
       "      <td>371657</td>\n",
       "      <td>378587</td>\n",
       "      <td>-157.823436</td>\n",
       "      <td>21.305782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>State</td>\n",
       "      <td>30711</td>\n",
       "      <td>31592</td>\n",
       "      <td>-134.511582</td>\n",
       "      <td>58.351418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Boise City</td>\n",
       "      <td>ID</td>\n",
       "      <td>State</td>\n",
       "      <td>185787</td>\n",
       "      <td>203529</td>\n",
       "      <td>-116.237655</td>\n",
       "      <td>43.613736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>WA</td>\n",
       "      <td>State</td>\n",
       "      <td>27514</td>\n",
       "      <td>45523</td>\n",
       "      <td>-122.893073</td>\n",
       "      <td>47.042418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Salem</td>\n",
       "      <td>OR</td>\n",
       "      <td>State</td>\n",
       "      <td>136924</td>\n",
       "      <td>152039</td>\n",
       "      <td>-123.029155</td>\n",
       "      <td>44.931109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id        name state capital  pop2000  pop2007   longitude   latitude\n",
       "0        1    Honolulu    HI   State   371657   378587 -157.823436  21.305782\n",
       "1        2      Juneau    AK   State    30711    31592 -134.511582  58.351418\n",
       "2        3  Boise City    ID   State   185787   203529 -116.237655  43.613736\n",
       "3        4     Olympia    WA   State    27514    45523 -122.893073  47.042418\n",
       "4        5       Salem    OR   State   136924   152039 -123.029155  44.931109"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the initial csv\n",
    "csv1 = 'data/updating_gis_content/capitals_1.csv'\n",
    "cities_df_1 = pd.read_csv(csv1)\n",
    "cities_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of records in this csv\n",
    "cities_df_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this dataset only contains 19 rows or 19 capital cities. It is not the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://python.playground.esri.com/portal/home/item.html?id=c766e56c866d4851ad4a8df6c8b60424' target='_blank'>\n",
       "                        <img src='https://python.playground.esri.com/portal/portalimages/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://python.playground.esri.com/portal/home/item.html?id=c766e56c866d4851ad4a8df6c8b60424' target='_blank'><b>USA Capitals spreadsheet</b>\n",
       "                        </a>\n",
       "                        <br/><img src='https://python.playground.esri.com/portal/home/js/jsapi/esri/css/images/item_type_icons/layers16.png' style=\"vertical-align:middle;\">CSV by arcgis_python\n",
       "                        <br/>Last Modified: June 26, 2017\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"USA Capitals spreadsheet\" type:CSV owner:arcgis_python>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the initial csv file and publish that as a web layer\n",
    "item_prop = {'title':'USA Capitals spreadsheet'}\n",
    "csv_item = gis.content.add(item_properties=item_prop, data=csv1)\n",
    "csv_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This spreadsheet has co-ordinates as `latitude` and `longitude` columns which will be used for geometries during publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://python.playground.esri.com/portal/home/item.html?id=75dc838480da4b608f9b85a531b3e027' target='_blank'>\n",
       "                        <img src='https://python.playground.esri.com/portal/portalimages/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://python.playground.esri.com/portal/home/item.html?id=75dc838480da4b608f9b85a531b3e027' target='_blank'><b>USA Capitals spreadsheet</b>\n",
       "                        </a>\n",
       "                        <br/><img src='https://python.playground.esri.com/portal/home/js/jsapi/esri/css/images/item_type_icons/featureshosted16.png' style=\"vertical-align:middle;\">Feature Layer Collection by arcgis_python\n",
       "                        <br/>Last Modified: June 26, 2017\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"USA Capitals spreadsheet\" type:Feature Service owner:arcgis_python>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# publish the csv item into a feature layer\n",
    "cities_item = csv_item.publish()\n",
    "cities_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://python.playground.esri.com/portal/home/item.html?id=75dc838480da4b608f9b85a531b3e027' target='_blank'>\n",
       "                        <img src='data:image/png;base64,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' width='200' height='133' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://python.playground.esri.com/portal/home/item.html?id=75dc838480da4b608f9b85a531b3e027' target='_blank'><b>USA Capitals</b>\n",
       "                        </a>\n",
       "                        <br/><img src='https://python.playground.esri.com/portal/home/js/jsapi/esri/css/images/item_type_icons/featureshosted16.png' style=\"vertical-align:middle;\">Feature Layer Collection by arcgis_python\n",
       "                        <br/>Last Modified: June 26, 2017\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"USA Capitals\" type:Feature Service owner:arcgis_python>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update the item metadata\n",
    "item_prop = {'title':'USA Capitals'}\n",
    "cities_item.update(item_properties = item_prop, thumbnail='data/updating_gis_content/capital_cities.png')\n",
    "cities_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply updates from the second spreadsheet\n",
    "The next set of updates have arrived and are stored in `capitals_2.csv`. We are told it contains corrections for the original set in addition to new features. We need to figure out which rows have changed, apply `update` operation on those, then apply `add` operation to new rows.\n",
    "\n",
    "To start with, let us read the second csv file. Note, in this sample, data is stored in csv. In reality, it could be from your enterprise database or any other data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>capital</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2007</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>LA</td>\n",
       "      <td>State</td>\n",
       "      <td>227818</td>\n",
       "      <td>228810</td>\n",
       "      <td>-91.140227</td>\n",
       "      <td>30.458091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Helena</td>\n",
       "      <td>MT</td>\n",
       "      <td>State</td>\n",
       "      <td>25780</td>\n",
       "      <td>26007</td>\n",
       "      <td>-112.027027</td>\n",
       "      <td>46.595809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bismarck</td>\n",
       "      <td>ND</td>\n",
       "      <td>State</td>\n",
       "      <td>55532</td>\n",
       "      <td>59344</td>\n",
       "      <td>-100.779000</td>\n",
       "      <td>46.813346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>SD</td>\n",
       "      <td>State</td>\n",
       "      <td>13876</td>\n",
       "      <td>14169</td>\n",
       "      <td>-100.336382</td>\n",
       "      <td>44.367964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>St. Paul</td>\n",
       "      <td>MN</td>\n",
       "      <td>State</td>\n",
       "      <td>287151</td>\n",
       "      <td>291643</td>\n",
       "      <td>-93.114118</td>\n",
       "      <td>44.954364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id         name state capital  pop2000  pop2007   longitude   latitude\n",
       "0       20  Baton Rouge    LA   State   227818   228810  -91.140227  30.458091\n",
       "1       21       Helena    MT   State    25780    26007 -112.027027  46.595809\n",
       "2       22     Bismarck    ND   State    55532    59344 -100.779000  46.813346\n",
       "3       23       Pierre    SD   State    13876    14169 -100.336382  44.367964\n",
       "4       24     St. Paul    MN   State   287151   291643  -93.114118  44.954364"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the second csv set\n",
    "csv2 = 'data/updating_gis_content/capitals_2.csv'\n",
    "cities_df_2 = pd.read_csv(csv2)\n",
    "cities_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dimensions of this csv\n",
    "cities_df_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying existing features that need to be updated\n",
    "\n",
    "To identify features that need to be updated, let us read the attribute table of the published feature layer and compare that against the second csv. To read the attribute table, we perform a `query()` on the feature layer which returns us an `arcgis.feature.FeatureSet` object. Refer to the guide pages on [accessing features from feature layers](/python/guide/working-with-feature-layers-and-features/) to learn more about this.\n",
    "\n",
    "Note, at this point, we could work with the `cities_df_1` dataframe we created from the original csv file. However, in practice you may not always have the original dataset or your feature layer might have undergone edits after it was published. Hence, we query the feature layer directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital</th>\n",
       "      <th>city_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>objectid</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2007</th>\n",
       "      <th>state</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State</td>\n",
       "      <td>1</td>\n",
       "      <td>21.305782</td>\n",
       "      <td>-157.823436</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>1</td>\n",
       "      <td>371657</td>\n",
       "      <td>378587</td>\n",
       "      <td>HI</td>\n",
       "      <td>{'x': -17568824.553, 'y': 2428377.352700006}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>2</td>\n",
       "      <td>58.351418</td>\n",
       "      <td>-134.511582</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>2</td>\n",
       "      <td>30711</td>\n",
       "      <td>31592</td>\n",
       "      <td>AK</td>\n",
       "      <td>{'x': -14973760.769500002, 'y': 8041504.674200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State</td>\n",
       "      <td>3</td>\n",
       "      <td>43.613736</td>\n",
       "      <td>-116.237655</td>\n",
       "      <td>Boise City</td>\n",
       "      <td>3</td>\n",
       "      <td>185787</td>\n",
       "      <td>203529</td>\n",
       "      <td>ID</td>\n",
       "      <td>{'x': -12939516.521100001, 'y': 5405860.248099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>State</td>\n",
       "      <td>4</td>\n",
       "      <td>47.042418</td>\n",
       "      <td>-122.893073</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>4</td>\n",
       "      <td>27514</td>\n",
       "      <td>45523</td>\n",
       "      <td>WA</td>\n",
       "      <td>{'x': -13680394.263900002, 'y': 5949000.547900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>State</td>\n",
       "      <td>5</td>\n",
       "      <td>44.931109</td>\n",
       "      <td>-123.029155</td>\n",
       "      <td>Salem</td>\n",
       "      <td>5</td>\n",
       "      <td>136924</td>\n",
       "      <td>152039</td>\n",
       "      <td>OR</td>\n",
       "      <td>{'x': -13695542.842799995, 'y': 5610682.544100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  capital  city_id   latitude   longitude        name  objectid  pop2000  \\\n",
       "0   State        1  21.305782 -157.823436    Honolulu         1   371657   \n",
       "1   State        2  58.351418 -134.511582      Juneau         2    30711   \n",
       "2   State        3  43.613736 -116.237655  Boise City         3   185787   \n",
       "3   State        4  47.042418 -122.893073     Olympia         4    27514   \n",
       "4   State        5  44.931109 -123.029155       Salem         5   136924   \n",
       "\n",
       "   pop2007 state                                              SHAPE  \n",
       "0   378587    HI       {'x': -17568824.553, 'y': 2428377.352700006}  \n",
       "1    31592    AK  {'x': -14973760.769500002, 'y': 8041504.674200...  \n",
       "2   203529    ID  {'x': -12939516.521100001, 'y': 5405860.248099...  \n",
       "3    45523    WA  {'x': -13680394.263900002, 'y': 5949000.547900...  \n",
       "4   152039    OR  {'x': -13695542.842799995, 'y': 5610682.544100...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_flayer = cities_item.layers[0]\n",
    "cities_fset = cities_flayer.query() #querying without any conditions returns all the features\n",
    "cities_fset.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `city_id` column is common between both the datasets. Next, let us perform an `inner` join with the table from feature layer as left and updated csv as right. Inner joins will yield those rows that are present in both tables. Learn more about [inner joins here](https://www.w3schools.com/sql/sql_join_inner.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital_x</th>\n",
       "      <th>city_id</th>\n",
       "      <th>latitude_x</th>\n",
       "      <th>longitude_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>objectid</th>\n",
       "      <th>pop2000_x</th>\n",
       "      <th>pop2007_x</th>\n",
       "      <th>state_x</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>name_y</th>\n",
       "      <th>state_y</th>\n",
       "      <th>capital_y</th>\n",
       "      <th>pop2000_y</th>\n",
       "      <th>pop2007_y</th>\n",
       "      <th>longitude_y</th>\n",
       "      <th>latitude_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State</td>\n",
       "      <td>4</td>\n",
       "      <td>47.042418</td>\n",
       "      <td>-122.893073</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>4</td>\n",
       "      <td>27514</td>\n",
       "      <td>45523</td>\n",
       "      <td>WA</td>\n",
       "      <td>{'x': -13680394.263900002, 'y': 5949000.547900...</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>WA</td>\n",
       "      <td>State</td>\n",
       "      <td>42514</td>\n",
       "      <td>45523</td>\n",
       "      <td>-122.893073</td>\n",
       "      <td>47.042418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>10</td>\n",
       "      <td>-41.145545</td>\n",
       "      <td>104.802046</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>10</td>\n",
       "      <td>53011</td>\n",
       "      <td>54750</td>\n",
       "      <td>WY</td>\n",
       "      <td>{'x': 11666510.350300007, 'y': -5033833.302499...</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>WY</td>\n",
       "      <td>State</td>\n",
       "      <td>53011</td>\n",
       "      <td>54750</td>\n",
       "      <td>-104.802046</td>\n",
       "      <td>41.145545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State</td>\n",
       "      <td>13</td>\n",
       "      <td>35.482309</td>\n",
       "      <td>-97.534991</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>13</td>\n",
       "      <td>506132</td>\n",
       "      <td>552556</td>\n",
       "      <td>OKK</td>\n",
       "      <td>{'x': -10857545.543799996, 'y': 4229619.674200...</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>OK</td>\n",
       "      <td>State</td>\n",
       "      <td>506132</td>\n",
       "      <td>552556</td>\n",
       "      <td>-97.534991</td>\n",
       "      <td>35.482309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>State</td>\n",
       "      <td>16</td>\n",
       "      <td>41.590936</td>\n",
       "      <td>-93.620864</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>16</td>\n",
       "      <td>200682</td>\n",
       "      <td>201257</td>\n",
       "      <td>IA</td>\n",
       "      <td>{'x': -10421826.864700003, 'y': 5099899.263700...</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>IA</td>\n",
       "      <td>State</td>\n",
       "      <td>198682</td>\n",
       "      <td>201257</td>\n",
       "      <td>-93.620864</td>\n",
       "      <td>41.590936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  capital_x  city_id  latitude_x  longitude_x         name_x  objectid  \\\n",
       "0     State        4   47.042418  -122.893073        Olympia         4   \n",
       "1     State       10  -41.145545   104.802046       Cheyenne        10   \n",
       "2     State       13   35.482309   -97.534991  Oklahoma City        13   \n",
       "3     State       16   41.590936   -93.620864     Des Moines        16   \n",
       "\n",
       "   pop2000_x  pop2007_x state_x  \\\n",
       "0      27514      45523      WA   \n",
       "1      53011      54750      WY   \n",
       "2     506132     552556     OKK   \n",
       "3     200682     201257      IA   \n",
       "\n",
       "                                               SHAPE         name_y state_y  \\\n",
       "0  {'x': -13680394.263900002, 'y': 5949000.547900...        Olympia      WA   \n",
       "1  {'x': 11666510.350300007, 'y': -5033833.302499...       Cheyenne      WY   \n",
       "2  {'x': -10857545.543799996, 'y': 4229619.674200...  Oklahoma City      OK   \n",
       "3  {'x': -10421826.864700003, 'y': 5099899.263700...     Des Moines      IA   \n",
       "\n",
       "  capital_y  pop2000_y  pop2007_y  longitude_y  latitude_y  \n",
       "0     State      42514      45523  -122.893073   47.042418  \n",
       "1     State      53011      54750  -104.802046   41.145545  \n",
       "2     State     506132     552556   -97.534991   35.482309  \n",
       "3     State     198682     201257   -93.620864   41.590936  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_rows = pd.merge(left = cities_fset.df, right = cities_df_2, how='inner',\n",
    "                       on = 'city_id')\n",
    "overlap_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, of 19 features in original and 36 features in second csv, 4 features are common. Inspecting the table, we find certain columns are updated, for instance, Cheyenne has its coordinates corrected, Oklahoma City has its state abbreviation corrected and similarly other cities have one of their attribute columns updated.\n",
    "\n",
    "We could either update individual attribute values for these 4 features or update all attribute values with the latest csv. Below, we are performing the latter as it is simple and fast.\n",
    "\n",
    "#### Perform updates to the existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_for_update = [] #list containing corrected features\n",
    "all_features = cities_fset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"geometry\": {\"x\": -17568824.553, \"y\": 2428377.352700006}, \"attributes\": {\"latitude\": 21.30578163, \"city_id\": 1, \"longitude\": -157.8234362, \"capital\": \"State\", \"name\": \"Honolulu\", \"objectid\": 1, \"pop2000\": 371657, \"pop2007\": 378587, \"state\": \"HI\"}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect one of the features\n",
    "all_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the X and Y geometry values are different from decimal degree coordinates present in Longitude and Latitude fields. To perform geometry edits, we need to project the coordinates to match that of the feature layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latestWkid': 3857, 'wkid': 102100}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the spatial reference of the features since we need to update the geometry\n",
    "cities_fset.spatial_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we prepare updated geometries and attributes for each of the 4 features we determined above. We use the `arcgis.geometry` module to `project` the coordinates from geographic to projected coordinate system. The cell below prints the original `Feature` objects followed by the updated ones. If you look closely, you can find the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"geometry\": {\"x\": -13680394.263900002, \"y\": 5949000.547900006}, \"attributes\": {\"latitude\": 47.04241817, \"city_id\": 4, \"longitude\": -122.8930726, \"capital\": \"State\", \"name\": \"Olympia\", \"objectid\": 4, \"pop2000\": 27514, \"pop2007\": 45523, \"state\": \"WA\"}}\n",
      "{\"geometry\": {\"x\": -13680394.2638528, \"y\": 5949000.54792491}, \"attributes\": {\"city_id\": 4, \"longitude\": -122.8930726, \"capital\": \"State\", \"name\": \"Olympia\", \"objectid\": 4, \"state\": \"WA\", \"pop2000\": 42514, \"pop2007\": 45523, \"latitude\": 47.04241817}}\n",
      "========================================================================\n",
      "{\"geometry\": {\"x\": 11666510.350300007, \"y\": -5033833.302499998}, \"attributes\": {\"latitude\": -41.14554516, \"city_id\": 10, \"longitude\": 104.8020456, \"capital\": \"State\", \"name\": \"Cheyenne\", \"objectid\": 10, \"pop2000\": 53011, \"pop2007\": 54750, \"state\": \"WY\"}}\n",
      "{\"geometry\": {\"x\": -11666510.350285435, \"y\": 5033833.302497153}, \"attributes\": {\"city_id\": 10, \"longitude\": -104.80204559999999, \"capital\": \"State\", \"name\": \"Cheyenne\", \"objectid\": 10, \"state\": \"WY\", \"pop2000\": 53011, \"pop2007\": 54750, \"latitude\": 41.14554516}}\n",
      "========================================================================\n",
      "{\"geometry\": {\"x\": -10857545.543799996, \"y\": 4229619.674200006}, \"attributes\": {\"latitude\": 35.48230867, \"city_id\": 13, \"longitude\": -97.5349911, \"capital\": \"State\", \"name\": \"Oklahoma City\", \"objectid\": 13, \"pop2000\": 506132, \"pop2007\": 552556, \"state\": \"OKK\"}}\n",
      "{\"geometry\": {\"x\": -10857545.54377847, \"y\": 4229619.674165817}, \"attributes\": {\"city_id\": 13, \"longitude\": -97.5349911, \"capital\": \"State\", \"name\": \"Oklahoma City\", \"objectid\": 13, \"state\": \"OK\", \"pop2000\": 506132, \"pop2007\": 552556, \"latitude\": 35.48230867}}\n",
      "========================================================================\n",
      "{\"geometry\": {\"x\": -10421826.864700003, \"y\": 5099899.263700008}, \"attributes\": {\"latitude\": 41.59093617, \"city_id\": 16, \"longitude\": -93.62086361, \"capital\": \"State\", \"name\": \"Des Moines\", \"objectid\": 16, \"pop2000\": 200682, \"pop2007\": 201257, \"state\": \"IA\"}}\n",
      "{\"geometry\": {\"x\": -10421826.864691716, \"y\": 5099899.263692743}, \"attributes\": {\"city_id\": 16, \"longitude\": -93.62086361, \"capital\": \"State\", \"name\": \"Des Moines\", \"objectid\": 16, \"state\": \"IA\", \"pop2000\": 198682, \"pop2007\": 201257, \"latitude\": 41.59093617}}\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "from arcgis import geometry #use geometry module to project Long,Lat to X and Y\n",
    "from copy import deepcopy\n",
    "\n",
    "for city_id in overlap_rows['city_id']:\n",
    "    # get the feature to be updated\n",
    "    original_feature = [f for f in all_features if f.attributes['city_id'] == city_id][0]\n",
    "    feature_to_be_updated = deepcopy(original_feature)\n",
    "    \n",
    "    print(str(original_feature))\n",
    "    \n",
    "    # get the matching row from csv\n",
    "    matching_row = cities_df_2.where(cities_df_2.city_id == city_id).dropna()\n",
    "    \n",
    "    #get geometries in the destination coordinate system\n",
    "    input_geometry = {'y':float(matching_row['latitude']),\n",
    "                       'x':float(matching_row['longitude'])}\n",
    "    output_geometry = geometry.project(geometries = [input_geometry],\n",
    "                                       in_sr = 4326, \n",
    "                                       out_sr = cities_fset.spatial_reference['latestWkid'],\n",
    "                                      gis = gis)\n",
    "    \n",
    "    # assign the updated values\n",
    "    feature_to_be_updated.geometry = output_geometry[0]\n",
    "    feature_to_be_updated.attributes['longitude'] = float(matching_row['longitude'])\n",
    "    feature_to_be_updated.attributes['city_id'] = int(matching_row['city_id'])\n",
    "    feature_to_be_updated.attributes['state'] = matching_row['state'].values[0]\n",
    "    feature_to_be_updated.attributes['capital'] = matching_row['capital'].values[0]\n",
    "    feature_to_be_updated.attributes['latitude'] = float(matching_row['latitude'])\n",
    "    feature_to_be_updated.attributes['name'] = matching_row['name'].values[0]\n",
    "    feature_to_be_updated.attributes['pop2000'] = int(matching_row['pop2000'])\n",
    "    feature_to_be_updated.attributes['pop2007'] = int(matching_row['pop2007'])\n",
    "    \n",
    "    #add this to the list of features to be updated\n",
    "    features_for_update.append(feature_to_be_updated)\n",
    "    \n",
    "    print(str(feature_to_be_updated))\n",
    "    print(\"========================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have constructed a list of features with updated values. We can use this list to perform updates on the feature layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"geometry\": {\"x\": -13680394.2638528, \"y\": 5949000.54792491}, \"attributes\": {\"city_id\": 4, \"longitude\": -122.8930726, \"capital\": \"State\", \"name\": \"Olympia\", \"objectid\": 4, \"state\": \"WA\", \"pop2000\": 42514, \"pop2007\": 45523, \"latitude\": 47.04241817}},\n",
       " {\"geometry\": {\"x\": -11666510.350285435, \"y\": 5033833.302497153}, \"attributes\": {\"city_id\": 10, \"longitude\": -104.80204559999999, \"capital\": \"State\", \"name\": \"Cheyenne\", \"objectid\": 10, \"state\": \"WY\", \"pop2000\": 53011, \"pop2007\": 54750, \"latitude\": 41.14554516}},\n",
       " {\"geometry\": {\"x\": -10857545.54377847, \"y\": 4229619.674165817}, \"attributes\": {\"city_id\": 13, \"longitude\": -97.5349911, \"capital\": \"State\", \"name\": \"Oklahoma City\", \"objectid\": 13, \"state\": \"OK\", \"pop2000\": 506132, \"pop2007\": 552556, \"latitude\": 35.48230867}},\n",
       " {\"geometry\": {\"x\": -10421826.864691716, \"y\": 5099899.263692743}, \"attributes\": {\"city_id\": 16, \"longitude\": -93.62086361, \"capital\": \"State\", \"name\": \"Des Moines\", \"objectid\": 16, \"state\": \"IA\", \"pop2000\": 198682, \"pop2007\": 201257, \"latitude\": 41.59093617}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_for_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the feature layer, call the `edit_features()` method of the `FeatureLayer` object and pass the list of features to the `updates` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addResults': [],\n",
       " 'attachments': {'addResults': [], 'deleteResults': [], 'updateResults': []},\n",
       " 'deleteResults': [],\n",
       " 'updateResults': [{'globalId': None, 'objectId': 4, 'success': True},\n",
       "  {'globalId': None, 'objectId': 10, 'success': True},\n",
       "  {'globalId': None, 'objectId': 13, 'success': True},\n",
       "  {'globalId': None, 'objectId': 16, 'success': True}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_flayer.edit_features(updates= features_for_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully applied corrections to those features which existed in the feature layer from the initial dataset. Next let us proceed to adding new features present only in the second csv file.\n",
    "\n",
    "#### Identifying new features that need to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8)\n"
     ]
    }
   ],
   "source": [
    "#select those rows in the capitals_2.csv that do not overlap with those in capitals_1.csv\n",
    "new_rows = cities_df_2[~cities_df_2['city_id'].isin(overlap_rows['city_id'])]\n",
    "print(new_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>capital</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2007</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>LA</td>\n",
       "      <td>State</td>\n",
       "      <td>227818</td>\n",
       "      <td>228810</td>\n",
       "      <td>-91.140227</td>\n",
       "      <td>30.458091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Helena</td>\n",
       "      <td>MT</td>\n",
       "      <td>State</td>\n",
       "      <td>25780</td>\n",
       "      <td>26007</td>\n",
       "      <td>-112.027027</td>\n",
       "      <td>46.595809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bismarck</td>\n",
       "      <td>ND</td>\n",
       "      <td>State</td>\n",
       "      <td>55532</td>\n",
       "      <td>59344</td>\n",
       "      <td>-100.779000</td>\n",
       "      <td>46.813346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>SD</td>\n",
       "      <td>State</td>\n",
       "      <td>13876</td>\n",
       "      <td>14169</td>\n",
       "      <td>-100.336382</td>\n",
       "      <td>44.367964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>St. Paul</td>\n",
       "      <td>MN</td>\n",
       "      <td>State</td>\n",
       "      <td>287151</td>\n",
       "      <td>291643</td>\n",
       "      <td>-93.114118</td>\n",
       "      <td>44.954364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id         name state capital  pop2000  pop2007   longitude   latitude\n",
       "0       20  Baton Rouge    LA   State   227818   228810  -91.140227  30.458091\n",
       "1       21       Helena    MT   State    25780    26007 -112.027027  46.595809\n",
       "2       22     Bismarck    ND   State    55532    59344 -100.779000  46.813346\n",
       "3       23       Pierre    SD   State    13876    14169 -100.336382  44.367964\n",
       "4       24     St. Paul    MN   State   287151   291643  -93.114118  44.954364"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, of the total 36 rows in the second csv, we have determined the 32 other rows which are new and need to be appended as new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new features\n",
    "Next, let us compose another `list` of `Feature` objects similar to earlier, from the `new_rows` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Baton Rouge\n",
      "Creating Helena\n",
      "Creating Bismarck\n",
      "Creating Pierre\n",
      "Creating St. Paul\n",
      "Creating Madison\n",
      "Creating Lansing\n",
      "Creating Augusta\n",
      "Creating Montpelier\n",
      "Creating Albany\n",
      "Creating Boston\n",
      "Creating Concord\n",
      "Creating Tallahassee\n",
      "Creating Jackson\n",
      "Creating Nashville\n",
      "Creating Montgomery\n",
      "Creating Springfield\n",
      "Creating Indianapolis\n",
      "Creating Frankfort\n",
      "Creating Columbus\n",
      "Creating Charleston\n",
      "Creating Atlanta\n",
      "Creating Columbia\n",
      "Creating Raleigh\n",
      "Creating Richmond\n",
      "Creating Harrisburg\n",
      "Creating Trenton\n",
      "Creating Dover\n",
      "Creating Washington\n",
      "Creating Annapolis\n",
      "Creating Hartford\n",
      "Creating Providence\n"
     ]
    }
   ],
   "source": [
    "features_to_be_added = []\n",
    "\n",
    "# get a template feature object\n",
    "template_feature = deepcopy(features_for_update[0])\n",
    "\n",
    "# loop through each row and add to the list of features to be added\n",
    "for row in new_rows.iterrows():\n",
    "    new_feature = deepcopy(template_feature)\n",
    "    \n",
    "    #print\n",
    "    print(\"Creating \" + row[1]['name'])\n",
    "    \n",
    "    #get geometries in the destination coordinate system\n",
    "    input_geometry = {'y':float(row[1]['latitude']),\n",
    "                       'x':float(row[1]['longitude'])}\n",
    "    output_geometry = geometry.project(geometries = [input_geometry],\n",
    "                                       in_sr = 4326, \n",
    "                                       out_sr = cities_fset.spatial_reference['latestWkid'],\n",
    "                                      gis = gis)\n",
    "    \n",
    "    # assign the updated values\n",
    "    new_feature.geometry = output_geometry[0]\n",
    "    new_feature.attributes['longitude'] = float(row[1]['longitude'])\n",
    "    new_feature.attributes['city_id'] = int(row[1]['city_id'])\n",
    "    new_feature.attributes['state'] = row[1]['state']\n",
    "    new_feature.attributes['capital'] = row[1]['capital']\n",
    "    new_feature.attributes['latitude'] = float(row[1]['latitude'])\n",
    "    new_feature.attributes['name'] = row[1]['name']\n",
    "    new_feature.attributes['pop2000'] = int(row[1]['pop2000'])\n",
    "    new_feature.attributes['pop2007'] = int(row[1]['pop2007'])\n",
    "    \n",
    "    #add this to the list of features to be updated\n",
    "    features_to_be_added.append(new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"geometry\": {\"x\": -10145683.671555312, \"y\": 3562570.141302621}, \"attributes\": {\"city_id\": 20, \"longitude\": -91.14022709999999, \"capital\": \"State\", \"name\": \"Baton Rouge\", \"objectid\": 4, \"state\": \"LA\", \"pop2000\": 227818, \"pop2007\": 228810, \"latitude\": 30.45809113}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at one of the features we created\n",
    "features_to_be_added[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have created a `list` of `Feature` objects with appropriate attributes and geometries. Next, to add these new features to the feature layer, call the `edit_features()` method of the `FeatureLayer` object and pass the list of `Feature` objects to the `adds` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addResults': [{'globalId': None, 'objectId': 20, 'success': True},\n",
       "  {'globalId': None, 'objectId': 21, 'success': True},\n",
       "  {'globalId': None, 'objectId': 22, 'success': True},\n",
       "  {'globalId': None, 'objectId': 23, 'success': True},\n",
       "  {'globalId': None, 'objectId': 24, 'success': True},\n",
       "  {'globalId': None, 'objectId': 25, 'success': True},\n",
       "  {'globalId': None, 'objectId': 26, 'success': True},\n",
       "  {'globalId': None, 'objectId': 27, 'success': True},\n",
       "  {'globalId': None, 'objectId': 28, 'success': True},\n",
       "  {'globalId': None, 'objectId': 29, 'success': True},\n",
       "  {'globalId': None, 'objectId': 30, 'success': True},\n",
       "  {'globalId': None, 'objectId': 31, 'success': True},\n",
       "  {'globalId': None, 'objectId': 32, 'success': True},\n",
       "  {'globalId': None, 'objectId': 33, 'success': True},\n",
       "  {'globalId': None, 'objectId': 34, 'success': True},\n",
       "  {'globalId': None, 'objectId': 35, 'success': True},\n",
       "  {'globalId': None, 'objectId': 36, 'success': True},\n",
       "  {'globalId': None, 'objectId': 37, 'success': True},\n",
       "  {'globalId': None, 'objectId': 38, 'success': True},\n",
       "  {'globalId': None, 'objectId': 39, 'success': True},\n",
       "  {'globalId': None, 'objectId': 40, 'success': True},\n",
       "  {'globalId': None, 'objectId': 41, 'success': True},\n",
       "  {'globalId': None, 'objectId': 42, 'success': True},\n",
       "  {'globalId': None, 'objectId': 43, 'success': True},\n",
       "  {'globalId': None, 'objectId': 44, 'success': True},\n",
       "  {'globalId': None, 'objectId': 45, 'success': True},\n",
       "  {'globalId': None, 'objectId': 46, 'success': True},\n",
       "  {'globalId': None, 'objectId': 47, 'success': True},\n",
       "  {'globalId': None, 'objectId': 48, 'success': True},\n",
       "  {'globalId': None, 'objectId': 49, 'success': True},\n",
       "  {'globalId': None, 'objectId': 50, 'success': True},\n",
       "  {'globalId': None, 'objectId': 51, 'success': True}],\n",
       " 'attachments': {'addResults': [], 'deleteResults': [], 'updateResults': []},\n",
       " 'deleteResults': [],\n",
       " 'updateResults': []}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_flayer.edit_features(adds = features_to_be_added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have successfully applied edits from second csv file. Next let us look at how we can apply edits from third csv file.\n",
    "\n",
    "### Apply edits from third spreadsheet\n",
    "The next set of updates have arrived and are stored in `capitals_annex.csv`. We are told it contains additional columns for each of the features that we want to add to the feature layer.\n",
    "\n",
    "To start with, let us read the third csv file. Note in this sample, data is stored in csv. In reality, it could be from your enterprise database or any other data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>ameri_es</th>\n",
       "      <th>asian</th>\n",
       "      <th>hawn_pl</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>males</th>\n",
       "      <th>females</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Census Designated Place</td>\n",
       "      <td>73093</td>\n",
       "      <td>6038</td>\n",
       "      <td>689</td>\n",
       "      <td>207588</td>\n",
       "      <td>25457</td>\n",
       "      <td>16229</td>\n",
       "      <td>182628</td>\n",
       "      <td>189029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>City and Borough</td>\n",
       "      <td>22969</td>\n",
       "      <td>248</td>\n",
       "      <td>3496</td>\n",
       "      <td>1438</td>\n",
       "      <td>116</td>\n",
       "      <td>1040</td>\n",
       "      <td>15469</td>\n",
       "      <td>15242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Boise City</td>\n",
       "      <td>City</td>\n",
       "      <td>171204</td>\n",
       "      <td>1437</td>\n",
       "      <td>1300</td>\n",
       "      <td>3870</td>\n",
       "      <td>302</td>\n",
       "      <td>8410</td>\n",
       "      <td>92014</td>\n",
       "      <td>93773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>City</td>\n",
       "      <td>36246</td>\n",
       "      <td>805</td>\n",
       "      <td>553</td>\n",
       "      <td>2473</td>\n",
       "      <td>125</td>\n",
       "      <td>1863</td>\n",
       "      <td>20319</td>\n",
       "      <td>22195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Salem</td>\n",
       "      <td>City</td>\n",
       "      <td>113746</td>\n",
       "      <td>1750</td>\n",
       "      <td>2064</td>\n",
       "      <td>3304</td>\n",
       "      <td>643</td>\n",
       "      <td>19973</td>\n",
       "      <td>68752</td>\n",
       "      <td>68172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id        name                    class   white  black  ameri_es  \\\n",
       "0        1    Honolulu  Census Designated Place   73093   6038       689   \n",
       "1        2      Juneau         City and Borough   22969    248      3496   \n",
       "2        3  Boise City                     City  171204   1437      1300   \n",
       "3        4     Olympia                     City   36246    805       553   \n",
       "4        5       Salem                     City  113746   1750      2064   \n",
       "\n",
       "    asian  hawn_pl  hispanic   males  females  \n",
       "0  207588    25457     16229  182628   189029  \n",
       "1    1438      116      1040   15469    15242  \n",
       "2    3870      302      8410   92014    93773  \n",
       "3    2473      125      1863   20319    22195  \n",
       "4    3304      643     19973   68752    68172  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the third csv set\n",
    "csv3 = 'data/updating_gis_content/capitals_annex.csv'\n",
    "cities_df_3 = pd.read_csv(csv3)\n",
    "cities_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 11)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the number of rows in the third csv\n",
    "cities_df_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `capitals_annex.csv` does not add new features, instead it adds additional attribute columns to existing features. It has 51 rows which were found to match the 19 + 32 rows from first and second csv files. The columns `City_ID` and `NAME` are common to all 3 spreadsheets. Next let us take a look at how we can append this additional attribute information to our feature layer.\n",
    "\n",
    "#### Inspecting existing fields of the feature layer\n",
    "The `manager` property of the `FeatureLayer` object exposes a set of methods to read and update the properties and definition of feature layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"alias\": \"city_id\",\n",
       "  \"name\": \"city_id\",\n",
       "  \"domain\": null,\n",
       "  \"length\": 10,\n",
       "  \"sqlType\": \"sqlTypeInteger\",\n",
       "  \"nullable\": true,\n",
       "  \"type\": \"esriFieldTypeInteger\",\n",
       "  \"editable\": true\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the existing list of fields on the cities feature layer\n",
    "cities_fields = cities_flayer.manager.properties.fields\n",
    "\n",
    "# Your feature layer may have multiple fields, \n",
    "# instead of printing all, let us take a look at one of the fields:\n",
    "cities_fields[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can see the representation of one of the fields. Let us loop through each of the fields and print the `name`, `alias`, `type` and `sqlType` properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectid \t|\t objectid \t|\t esriFieldTypeOID \t|\t sqlTypeInteger\n",
      "city_id \t|\t city_id \t|\t esriFieldTypeInteger \t|\t sqlTypeInteger\n",
      "name \t|\t name \t|\t esriFieldTypeString \t|\t sqlTypeVarchar\n",
      "state \t|\t state \t|\t esriFieldTypeString \t|\t sqlTypeVarchar\n",
      "capital \t|\t capital \t|\t esriFieldTypeString \t|\t sqlTypeVarchar\n",
      "pop2000 \t|\t pop2000 \t|\t esriFieldTypeInteger \t|\t sqlTypeInteger\n",
      "pop2007 \t|\t pop2007 \t|\t esriFieldTypeInteger \t|\t sqlTypeInteger\n",
      "longitude \t|\t longitude \t|\t esriFieldTypeDouble \t|\t sqlTypeNumeric\n",
      "latitude \t|\t latitude \t|\t esriFieldTypeDouble \t|\t sqlTypeNumeric\n"
     ]
    }
   ],
   "source": [
    "for field in cities_fields:\n",
    "    print(field.name, \"\\t|\\t\", field.alias, \"\\t|\\t\", field.type, \"\\t|\\t\", field.sqlType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing additional columns to add to the feature layer\n",
    "Now that we have an idea of how the fields are defined, we can go ahead and append new fields to the layer's definition. Once we compose a list of new fields, by calling the `add_to_definition()` method we can push those changes to the feature layer. Once the feature layer's definition is updated with new fields, we can loop through each feature and add the appropriate attribute values.\n",
    "\n",
    "To compose a list of new fields to be added, we start by making a copy of one of the fields as a template and start editing it. One easy part in this example is, all new fields that need to be added except one, are of the same data type: integer. With your data, this may not be the case. In such instances, you can add each field individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias': 'city_id',\n",
       " 'domain': None,\n",
       " 'editable': True,\n",
       " 'length': 10,\n",
       " 'name': 'city_id',\n",
       " 'nullable': True,\n",
       " 'sqlType': 'sqlTypeInteger',\n",
       " 'type': 'esriFieldTypeInteger'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a template field\n",
    "template_field = dict(deepcopy(cities_fields[1]))\n",
    "template_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use pandas to get the list of fields that are **new** in spread sheet 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ameri_es',\n",
       " 'asian',\n",
       " 'black',\n",
       " 'class',\n",
       " 'females',\n",
       " 'hawn_pl',\n",
       " 'hispanic',\n",
       " 'males',\n",
       " 'white']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of new fields to add from the third spreadsheet, that are not in spread sheets 1,2\n",
    "new_field_names = list(cities_df_3.columns.difference(cities_df_1.columns))\n",
    "new_field_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop though each new field name and create a field dictionary using the template we created earlier. Except the field titled `class` all other fields are of type `integer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields_to_be_added = []\n",
    "for new_field_name in new_field_names:\n",
    "    current_field = deepcopy(template_field)\n",
    "    if new_field_name.lower() == 'class':\n",
    "        current_field['sqlType'] = 'sqlTypeVarchar'\n",
    "        current_field['type'] = 'esriFieldTypeString'\n",
    "        current_field['length'] = 8000\n",
    "        \n",
    "    current_field['name'] = new_field_name.lower()\n",
    "    current_field['alias'] = new_field_name\n",
    "    fields_to_be_added.append(current_field)\n",
    "    \n",
    "len(fields_to_be_added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias': 'class',\n",
       " 'domain': None,\n",
       " 'editable': True,\n",
       " 'length': 8000,\n",
       " 'name': 'class',\n",
       " 'nullable': True,\n",
       " 'sqlType': 'sqlTypeVarchar',\n",
       " 'type': 'esriFieldTypeString'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect one of the fields\n",
    "fields_to_be_added[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding additional fields to the feature layer\n",
    "The list of new fields we composed can be pushed to the server by calling `add_to_definition()` method on the `manager` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_flayer.manager.add_to_definition({'fields':fields_to_be_added})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have successfully added new fields to our feature layer. Let us verify the new columns show up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cities_fields = cities_flayer.manager.properties.fields\n",
    "len(new_cities_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectid\t|\t esriFieldTypeOID\n",
      "city_id\t|\t esriFieldTypeInteger\n",
      "name\t|\t esriFieldTypeString\n",
      "state\t|\t esriFieldTypeString\n",
      "capital\t|\t esriFieldTypeString\n",
      "pop2000\t|\t esriFieldTypeInteger\n",
      "pop2007\t|\t esriFieldTypeInteger\n",
      "longitude\t|\t esriFieldTypeDouble\n",
      "latitude\t|\t esriFieldTypeDouble\n",
      "ameri_es\t|\t esriFieldTypeInteger\n",
      "asian\t|\t esriFieldTypeInteger\n",
      "black\t|\t esriFieldTypeInteger\n",
      "class\t|\t esriFieldTypeString\n",
      "females\t|\t esriFieldTypeInteger\n",
      "hawn_pl\t|\t esriFieldTypeInteger\n",
      "hispanic\t|\t esriFieldTypeInteger\n",
      "males\t|\t esriFieldTypeInteger\n",
      "white\t|\t esriFieldTypeInteger\n"
     ]
    }
   ],
   "source": [
    "for field in new_cities_fields:\n",
    "    print(field.name + \"\\t|\\t\", field.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding attribute values to the new columns\n",
    "Next we can loop through each row in the third csv and add the new attribute values for these newly created columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a fresh query on the feature layer so it includes the new features from\n",
    "# csv2 and new columns from csv3\n",
    "cities_fset2 = cities_flayer.query()\n",
    "cities_features2 = cities_fset2.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each row in the third spreadsheet, find the corresponding feature by matching the `city_id` value and apply the attribute values for the new fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Adding additional attributes for: Honolulu\n",
      "2 Adding additional attributes for: Juneau\n",
      "3 Adding additional attributes for: Boise City\n",
      "4 Adding additional attributes for: Olympia\n",
      "5 Adding additional attributes for: Salem\n",
      "6 Adding additional attributes for: Carson\n",
      "7 Adding additional attributes for: Sacramento\n",
      "8 Adding additional attributes for: Phoenix\n",
      "9 Adding additional attributes for: Salt Lake City\n",
      "10 Adding additional attributes for: Cheyenne\n",
      "11 Adding additional attributes for: Denver\n",
      "12 Adding additional attributes for: Santa Fe\n",
      "13 Adding additional attributes for: Oklahoma City\n",
      "14 Adding additional attributes for: Topeka\n",
      "15 Adding additional attributes for: Lincoln\n",
      "16 Adding additional attributes for: Des Moines\n",
      "17 Adding additional attributes for: Jefferson City\n",
      "18 Adding additional attributes for: Little Rock\n",
      "19 Adding additional attributes for: Austin\n",
      "20 Adding additional attributes for: Baton Rouge\n",
      "21 Adding additional attributes for: Helena\n",
      "22 Adding additional attributes for: Bismarck\n",
      "23 Adding additional attributes for: Pierre\n",
      "24 Adding additional attributes for: St. Paul\n",
      "25 Adding additional attributes for: Madison\n",
      "26 Adding additional attributes for: Lansing\n",
      "27 Adding additional attributes for: Augusta\n",
      "28 Adding additional attributes for: Montpelier\n",
      "29 Adding additional attributes for: Albany\n",
      "30 Adding additional attributes for: Boston\n",
      "31 Adding additional attributes for: Concord\n",
      "32 Adding additional attributes for: Tallahassee\n",
      "33 Adding additional attributes for: Jackson\n",
      "34 Adding additional attributes for: Nashville\n",
      "35 Adding additional attributes for: Montgomery\n",
      "36 Adding additional attributes for: Springfield\n",
      "37 Adding additional attributes for: Indianapolis\n",
      "38 Adding additional attributes for: Frankfort\n",
      "39 Adding additional attributes for: Columbus\n",
      "40 Adding additional attributes for: Charleston\n",
      "41 Adding additional attributes for: Atlanta\n",
      "42 Adding additional attributes for: Columbia\n",
      "43 Adding additional attributes for: Raleigh\n",
      "44 Adding additional attributes for: Richmond\n",
      "45 Adding additional attributes for: Harrisburg\n",
      "46 Adding additional attributes for: Trenton\n",
      "47 Adding additional attributes for: Dover\n",
      "48 Adding additional attributes for: Washington\n",
      "49 Adding additional attributes for: Annapolis\n",
      "50 Adding additional attributes for: Hartford\n",
      "51 Adding additional attributes for: Providence\n"
     ]
    }
   ],
   "source": [
    "features_for_update = []\n",
    "for city_id in cities_df_3['city_id']:\n",
    "    # get the matching row from csv\n",
    "    matching_row = cities_df_3.where(cities_df_3.city_id == city_id).dropna()\n",
    "    \n",
    "    print(str(city_id) + \" Adding additional attributes for: \" + matching_row['name'].values[0])\n",
    "    \n",
    "    # get the feature to be updated\n",
    "    original_feature = [f for f in cities_features2 if f.attributes['city_id'] == city_id][0]\n",
    "    feature_to_be_updated = deepcopy(original_feature)\n",
    "    \n",
    "    # assign the updated values\n",
    "    feature_to_be_updated.attributes['class'] = matching_row['class'].values[0]\n",
    "    feature_to_be_updated.attributes['white'] = int(matching_row['white'])\n",
    "    feature_to_be_updated.attributes['black'] = int(matching_row['black'])\n",
    "    feature_to_be_updated.attributes['ameri_es'] = int(matching_row['ameri_es'])\n",
    "    feature_to_be_updated.attributes['asian'] = int(matching_row['asian'])\n",
    "    feature_to_be_updated.attributes['hawn_pl'] = int(matching_row['hawn_pl'])\n",
    "    feature_to_be_updated.attributes['hispanic'] = int(matching_row['hispanic'])\n",
    "    feature_to_be_updated.attributes['males'] = int(matching_row['males'])\n",
    "    feature_to_be_updated.attributes['females'] = int(matching_row['females'])\n",
    "    \n",
    "    #add this to the list of features to be updated\n",
    "    features_for_update.append(feature_to_be_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"geometry\": {\"x\": -7950674.8190312665, \"y\": 5134585.3226086125}, \"attributes\": {\"latitude\": 41.82355466, \"city_id\": 51, \"longitude\": -71.42212709, \"hawn_pl\": 270, \"capital\": \"State\", \"black\": 25243, \"ameri_es\": 1975, \"males\": 83035, \"females\": 90583, \"white\": 94666, \"asian\": 10432, \"objectid\": 51, \"hispanic\": 52146, \"name\": \"Providence\", \"pop2000\": 173618, \"pop2007\": 183731, \"class\": \"City\", \"state\": \"RI\"}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect one of the features\n",
    "features_for_update[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addResults': [],\n",
       " 'attachments': {'addResults': [], 'deleteResults': [], 'updateResults': []},\n",
       " 'deleteResults': [],\n",
       " 'updateResults': [{'globalId': None, 'objectId': 1, 'success': True},\n",
       "  {'globalId': None, 'objectId': 2, 'success': True},\n",
       "  {'globalId': None, 'objectId': 3, 'success': True},\n",
       "  {'globalId': None, 'objectId': 4, 'success': True},\n",
       "  {'globalId': None, 'objectId': 5, 'success': True},\n",
       "  {'globalId': None, 'objectId': 6, 'success': True},\n",
       "  {'globalId': None, 'objectId': 7, 'success': True},\n",
       "  {'globalId': None, 'objectId': 8, 'success': True},\n",
       "  {'globalId': None, 'objectId': 9, 'success': True},\n",
       "  {'globalId': None, 'objectId': 10, 'success': True},\n",
       "  {'globalId': None, 'objectId': 11, 'success': True},\n",
       "  {'globalId': None, 'objectId': 12, 'success': True},\n",
       "  {'globalId': None, 'objectId': 13, 'success': True},\n",
       "  {'globalId': None, 'objectId': 14, 'success': True},\n",
       "  {'globalId': None, 'objectId': 15, 'success': True},\n",
       "  {'globalId': None, 'objectId': 16, 'success': True},\n",
       "  {'globalId': None, 'objectId': 17, 'success': True},\n",
       "  {'globalId': None, 'objectId': 18, 'success': True},\n",
       "  {'globalId': None, 'objectId': 19, 'success': True},\n",
       "  {'globalId': None, 'objectId': 20, 'success': True},\n",
       "  {'globalId': None, 'objectId': 21, 'success': True},\n",
       "  {'globalId': None, 'objectId': 22, 'success': True},\n",
       "  {'globalId': None, 'objectId': 23, 'success': True},\n",
       "  {'globalId': None, 'objectId': 24, 'success': True},\n",
       "  {'globalId': None, 'objectId': 25, 'success': True},\n",
       "  {'globalId': None, 'objectId': 26, 'success': True},\n",
       "  {'globalId': None, 'objectId': 27, 'success': True},\n",
       "  {'globalId': None, 'objectId': 28, 'success': True},\n",
       "  {'globalId': None, 'objectId': 29, 'success': True},\n",
       "  {'globalId': None, 'objectId': 30, 'success': True},\n",
       "  {'globalId': None, 'objectId': 31, 'success': True},\n",
       "  {'globalId': None, 'objectId': 32, 'success': True},\n",
       "  {'globalId': None, 'objectId': 33, 'success': True},\n",
       "  {'globalId': None, 'objectId': 34, 'success': True},\n",
       "  {'globalId': None, 'objectId': 35, 'success': True},\n",
       "  {'globalId': None, 'objectId': 36, 'success': True},\n",
       "  {'globalId': None, 'objectId': 37, 'success': True},\n",
       "  {'globalId': None, 'objectId': 38, 'success': True},\n",
       "  {'globalId': None, 'objectId': 39, 'success': True},\n",
       "  {'globalId': None, 'objectId': 40, 'success': True},\n",
       "  {'globalId': None, 'objectId': 41, 'success': True},\n",
       "  {'globalId': None, 'objectId': 42, 'success': True},\n",
       "  {'globalId': None, 'objectId': 43, 'success': True},\n",
       "  {'globalId': None, 'objectId': 44, 'success': True},\n",
       "  {'globalId': None, 'objectId': 45, 'success': True},\n",
       "  {'globalId': None, 'objectId': 46, 'success': True},\n",
       "  {'globalId': None, 'objectId': 47, 'success': True},\n",
       "  {'globalId': None, 'objectId': 48, 'success': True},\n",
       "  {'globalId': None, 'objectId': 49, 'success': True},\n",
       "  {'globalId': None, 'objectId': 50, 'success': True},\n",
       "  {'globalId': None, 'objectId': 51, 'success': True}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the edits to the feature layer\n",
    "cities_flayer.edit_features(updates= features_for_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the changes made so far\n",
    "Let us run another query on the feature layer and visualize a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ameri_es</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>capital</th>\n",
       "      <th>city_id</th>\n",
       "      <th>class</th>\n",
       "      <th>females</th>\n",
       "      <th>hawn_pl</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>males</th>\n",
       "      <th>name</th>\n",
       "      <th>objectid</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2007</th>\n",
       "      <th>state</th>\n",
       "      <th>white</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>689</td>\n",
       "      <td>207588</td>\n",
       "      <td>6038</td>\n",
       "      <td>State</td>\n",
       "      <td>1</td>\n",
       "      <td>Census Designated Place</td>\n",
       "      <td>189029</td>\n",
       "      <td>25457</td>\n",
       "      <td>16229</td>\n",
       "      <td>21.305782</td>\n",
       "      <td>-157.823436</td>\n",
       "      <td>182628</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>1</td>\n",
       "      <td>371657</td>\n",
       "      <td>378587</td>\n",
       "      <td>HI</td>\n",
       "      <td>73093</td>\n",
       "      <td>{'x': -17568824.553, 'y': 2428377.352700006}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3496</td>\n",
       "      <td>1438</td>\n",
       "      <td>248</td>\n",
       "      <td>State</td>\n",
       "      <td>2</td>\n",
       "      <td>City and Borough</td>\n",
       "      <td>15242</td>\n",
       "      <td>116</td>\n",
       "      <td>1040</td>\n",
       "      <td>58.351418</td>\n",
       "      <td>-134.511582</td>\n",
       "      <td>15469</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>2</td>\n",
       "      <td>30711</td>\n",
       "      <td>31592</td>\n",
       "      <td>AK</td>\n",
       "      <td>22969</td>\n",
       "      <td>{'x': -14973760.769500002, 'y': 8041504.674200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300</td>\n",
       "      <td>3870</td>\n",
       "      <td>1437</td>\n",
       "      <td>State</td>\n",
       "      <td>3</td>\n",
       "      <td>City</td>\n",
       "      <td>93773</td>\n",
       "      <td>302</td>\n",
       "      <td>8410</td>\n",
       "      <td>43.613736</td>\n",
       "      <td>-116.237655</td>\n",
       "      <td>92014</td>\n",
       "      <td>Boise City</td>\n",
       "      <td>3</td>\n",
       "      <td>185787</td>\n",
       "      <td>203529</td>\n",
       "      <td>ID</td>\n",
       "      <td>171204</td>\n",
       "      <td>{'x': -12939516.521100001, 'y': 5405860.248099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>553</td>\n",
       "      <td>2473</td>\n",
       "      <td>805</td>\n",
       "      <td>State</td>\n",
       "      <td>4</td>\n",
       "      <td>City</td>\n",
       "      <td>22195</td>\n",
       "      <td>125</td>\n",
       "      <td>1863</td>\n",
       "      <td>47.042418</td>\n",
       "      <td>-122.893073</td>\n",
       "      <td>20319</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>4</td>\n",
       "      <td>42514</td>\n",
       "      <td>45523</td>\n",
       "      <td>WA</td>\n",
       "      <td>36246</td>\n",
       "      <td>{'x': -13680394.263852797, 'y': 5949000.547924...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2064</td>\n",
       "      <td>3304</td>\n",
       "      <td>1750</td>\n",
       "      <td>State</td>\n",
       "      <td>5</td>\n",
       "      <td>City</td>\n",
       "      <td>68172</td>\n",
       "      <td>643</td>\n",
       "      <td>19973</td>\n",
       "      <td>44.931109</td>\n",
       "      <td>-123.029155</td>\n",
       "      <td>68752</td>\n",
       "      <td>Salem</td>\n",
       "      <td>5</td>\n",
       "      <td>136924</td>\n",
       "      <td>152039</td>\n",
       "      <td>OR</td>\n",
       "      <td>113746</td>\n",
       "      <td>{'x': -13695542.842799995, 'y': 5610682.544100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ameri_es   asian  black capital  city_id                    class  females  \\\n",
       "0       689  207588   6038   State        1  Census Designated Place   189029   \n",
       "1      3496    1438    248   State        2         City and Borough    15242   \n",
       "2      1300    3870   1437   State        3                     City    93773   \n",
       "3       553    2473    805   State        4                     City    22195   \n",
       "4      2064    3304   1750   State        5                     City    68172   \n",
       "\n",
       "   hawn_pl  hispanic   latitude   longitude   males        name  objectid  \\\n",
       "0    25457     16229  21.305782 -157.823436  182628    Honolulu         1   \n",
       "1      116      1040  58.351418 -134.511582   15469      Juneau         2   \n",
       "2      302      8410  43.613736 -116.237655   92014  Boise City         3   \n",
       "3      125      1863  47.042418 -122.893073   20319     Olympia         4   \n",
       "4      643     19973  44.931109 -123.029155   68752       Salem         5   \n",
       "\n",
       "   pop2000  pop2007 state   white  \\\n",
       "0   371657   378587    HI   73093   \n",
       "1    30711    31592    AK   22969   \n",
       "2   185787   203529    ID  171204   \n",
       "3    42514    45523    WA   36246   \n",
       "4   136924   152039    OR  113746   \n",
       "\n",
       "                                               SHAPE  \n",
       "0       {'x': -17568824.553, 'y': 2428377.352700006}  \n",
       "1  {'x': -14973760.769500002, 'y': 8041504.674200...  \n",
       "2  {'x': -12939516.521100001, 'y': 5405860.248099...  \n",
       "3  {'x': -13680394.263852797, 'y': 5949000.547924...  \n",
       "4  {'x': -13695542.842799995, 'y': 5610682.544100...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_fset3 = cities_flayer.query()\n",
    "cities_fset3.df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this sample, we observed an edit intensive method to keep feature layers updated. We published data from first spreadsheet as a feature layer. We then updated existing features from second spread sheet (used geometry module to project the coordinates in the process), and added new features. The third spreadsheet presented additional attribute columns which were added to the feature layer by editing its definition and then updating the features with this additional data.\n",
    "\n",
    "This method is editing intensive and you may choose this when the number of features to edit is less or if you needed to selectively update certain features as updates come in.\n",
    "\n",
    "An alternate method is to overwrite the feature layer altogether when you always have current information coming in. This method is explained in the sample [Overwriting feature layers](/python/sample-notebook/overwriting-feature-layers)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
